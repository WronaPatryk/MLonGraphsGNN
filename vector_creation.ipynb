{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio files and spectrograms to vector transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import re\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "from source.utils import cut_samples_to_n, train_val_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list, valid_list, test_list = train_val_test_labels(\"audio/training_list.txt\", \"audio/validation_list.txt\", \"audio/testing_list.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'audio/004ae714_nohash_1.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m train_vectors \u001b[39m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m path \u001b[39min\u001b[39;00m train_list:\n\u001b[1;32m----> 3\u001b[0m     sample_rate, samples \u001b[39m=\u001b[39m wavfile\u001b[39m.\u001b[39;49mread(\u001b[39m\"\u001b[39;49m\u001b[39maudio/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m path)\n\u001b[0;32m      4\u001b[0m     train_vectors\u001b[39m.\u001b[39mappend(cut_samples_to_n(samples))\n\u001b[0;32m      5\u001b[0m train_vectors_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(train_vectors)\n",
      "File \u001b[1;32mc:\\Users\\marty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\io\\wavfile.py:647\u001b[0m, in \u001b[0;36mread\u001b[1;34m(filename, mmap)\u001b[0m\n\u001b[0;32m    645\u001b[0m     mmap \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 647\u001b[0m     fid \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    649\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     file_size, is_big_endian \u001b[39m=\u001b[39m _read_riff_chunk(fid)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'audio/004ae714_nohash_1.wav'"
     ]
    }
   ],
   "source": [
    "train_vectors = []\n",
    "for path in train_list:\n",
    "    sample_rate, samples = wavfile.read(\"audio/\" + path)\n",
    "    train_vectors.append(cut_samples_to_n(samples))\n",
    "train_vectors_df = pd.DataFrame(train_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors_df.to_csv(\"data/raw_audio/train.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_vectors = []\n",
    "for path in valid_list:\n",
    "    sample_rate, samples = wavfile.read(\"audio/\" + path)\n",
    "    val_vectors.append(cut_samples_to_n(samples), os.path.dirname(path))\n",
    "val_vectors_df = pd.DataFrame(val_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_vectors_df.to_csv(\"data/raw_audio/valid.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors = []\n",
    "for path in test_list:\n",
    "    sample_rate, samples = wavfile.read(\"audio/\" + path)\n",
    "    test_vectors.append(np.append(cut_samples_to_n(samples), os.path.dirname(path)))\n",
    "test_vectors_df = pd.DataFrame(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors_df.to_csv(\"data/raw_audio/test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
