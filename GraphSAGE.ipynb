{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef413dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from source.utils import train_val_test_labels, labels_to_numbers\n",
    "from source.structure_modeling import torch_geometric_data_from_graph\n",
    "from source.models import GraphSAGE, GraphSAGE2, train_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "965c4213",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cd31879",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectr_dir = \"spectrograms/\"\n",
    "labels_train, labels_valid, labels_test = train_val_test_labels(spectr_dir, \"spectr_train_list.txt\", \"spectr_valid_list.txt\", \"spectr_test_list.txt\", index_col=0, header=0, pos=1)\n",
    "labels = labels_train + labels_valid + labels_test\n",
    "label_names, labels_nr = labels_to_numbers(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c71b2b54",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "368b4e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectr2_dir = \"data/spectrogram2/\"\n",
    "train_df = pd.read_csv(spectr2_dir+\"train.csv\", header = None)\n",
    "valid_df = pd.read_csv(spectr2_dir+\"valid.csv\", header = None)\n",
    "test_df = pd.read_csv(spectr2_dir+\"test.csv\", header = None)\n",
    "df = pd.concat([train_df, valid_df, test_df])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98f6f5db",
   "metadata": {},
   "source": [
    "# Building graph from the data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "983c2eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_adjlist(\"graphs/spect2_kNN.adjlist\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69a63816",
   "metadata": {},
   "source": [
    "## Create torch_geometric.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f50640a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch_geometric_data_from_graph(G, df, labels_nr, len(labels_train), len(labels_valid), len(labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76d54cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 23682\n",
      "Number of edges: 151290\n",
      "Number of features: 64\n",
      "Number of classes: 10\n",
      "Average node degree: 6.39\n",
      "Number of training nodes: 18538\n",
      "Number of validation nodes: 2567\n",
      "Number of testing nodes: 2577\n",
      "Training node label rate: 0.78\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Number of features: {data.num_features}')\n",
    "print(f'Number of classes: {data.num_classes}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Number of validation nodes: {data.valid_mask.sum()}')\n",
    "print(f'Number of testing nodes: {data.test_mask.sum()}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32761a6b",
   "metadata": {},
   "source": [
    "## GraphSAGE - best architecture search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd539e9c",
   "metadata": {},
   "source": [
    "## GraphSAGE - single hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00c12042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 3.1185, Acc: 0.1036\n",
      "Epoch: 001, Loss: 2.4697, Acc: 0.1075\n",
      "Epoch: 002, Loss: 2.3273, Acc: 0.1126\n",
      "Epoch: 003, Loss: 2.3036, Acc: 0.1110\n",
      "Epoch: 004, Loss: 2.2944, Acc: 0.1079\n",
      "Epoch: 005, Loss: 2.2859, Acc: 0.1075\n",
      "Epoch: 006, Loss: 2.2797, Acc: 0.1079\n",
      "Epoch: 007, Loss: 2.2717, Acc: 0.1067\n",
      "Epoch: 008, Loss: 2.2637, Acc: 0.1071\n",
      "Epoch: 009, Loss: 2.2535, Acc: 0.1126\n",
      "Epoch: 010, Loss: 2.2461, Acc: 0.1141\n",
      "Epoch: 011, Loss: 2.2412, Acc: 0.1106\n",
      "Epoch: 012, Loss: 2.2283, Acc: 0.1138\n",
      "Epoch: 013, Loss: 2.2230, Acc: 0.1138\n",
      "Epoch: 014, Loss: 2.2125, Acc: 0.1126\n",
      "Epoch: 015, Loss: 2.2009, Acc: 0.1204\n",
      "Epoch: 016, Loss: 2.1965, Acc: 0.1227\n",
      "Epoch: 017, Loss: 2.1919, Acc: 0.1215\n",
      "Epoch: 018, Loss: 2.1838, Acc: 0.1235\n",
      "Epoch: 019, Loss: 2.1770, Acc: 0.1227\n",
      "Epoch: 020, Loss: 2.1692, Acc: 0.1231\n",
      "Epoch: 021, Loss: 2.1620, Acc: 0.1289\n",
      "Epoch: 022, Loss: 2.1553, Acc: 0.1305\n",
      "Epoch: 023, Loss: 2.1450, Acc: 0.1363\n",
      "Epoch: 024, Loss: 2.1264, Acc: 0.1488\n",
      "Epoch: 025, Loss: 2.1047, Acc: 0.1675\n",
      "Epoch: 026, Loss: 2.0893, Acc: 0.1663\n",
      "Epoch: 027, Loss: 2.0947, Acc: 0.1691\n",
      "Epoch: 028, Loss: 2.0807, Acc: 0.1757\n",
      "Epoch: 029, Loss: 2.0591, Acc: 0.1847\n",
      "Epoch: 030, Loss: 2.0536, Acc: 0.1858\n",
      "Epoch: 031, Loss: 2.0591, Acc: 0.1893\n",
      "Epoch: 032, Loss: 2.0442, Acc: 0.1924\n",
      "Epoch: 033, Loss: 2.0386, Acc: 0.1905\n",
      "Epoch: 034, Loss: 2.0268, Acc: 0.1866\n",
      "Epoch: 035, Loss: 2.0099, Acc: 0.1847\n",
      "Epoch: 036, Loss: 2.0112, Acc: 0.1905\n",
      "Epoch: 037, Loss: 2.0017, Acc: 0.1928\n",
      "Epoch: 038, Loss: 1.9963, Acc: 0.1924\n",
      "Epoch: 039, Loss: 1.9861, Acc: 0.1967\n",
      "Epoch: 040, Loss: 1.9904, Acc: 0.1963\n",
      "Epoch: 041, Loss: 1.9781, Acc: 0.1967\n",
      "Epoch: 042, Loss: 1.9750, Acc: 0.2010\n",
      "Epoch: 043, Loss: 1.9706, Acc: 0.2034\n",
      "Epoch: 044, Loss: 1.9635, Acc: 0.2104\n",
      "Epoch: 045, Loss: 1.9599, Acc: 0.2053\n",
      "Epoch: 046, Loss: 1.9586, Acc: 0.2072\n",
      "Epoch: 047, Loss: 1.9531, Acc: 0.2104\n",
      "Epoch: 048, Loss: 1.9509, Acc: 0.2123\n",
      "Epoch: 049, Loss: 1.9565, Acc: 0.2111\n",
      "Epoch: 050, Loss: 1.9410, Acc: 0.2119\n",
      "Epoch: 051, Loss: 1.9370, Acc: 0.2185\n",
      "Epoch: 052, Loss: 1.9394, Acc: 0.2236\n",
      "Epoch: 053, Loss: 1.9246, Acc: 0.2236\n",
      "Epoch: 054, Loss: 1.9393, Acc: 0.2252\n",
      "Epoch: 055, Loss: 1.9297, Acc: 0.2310\n",
      "Epoch: 056, Loss: 1.9244, Acc: 0.2314\n",
      "Epoch: 057, Loss: 1.9184, Acc: 0.2310\n",
      "Epoch: 058, Loss: 1.9138, Acc: 0.2333\n",
      "Epoch: 059, Loss: 1.9093, Acc: 0.2353\n",
      "Epoch: 060, Loss: 1.9046, Acc: 0.2380\n",
      "Epoch: 061, Loss: 1.9053, Acc: 0.2407\n",
      "Epoch: 062, Loss: 1.8955, Acc: 0.2415\n",
      "Epoch: 063, Loss: 1.9091, Acc: 0.2400\n",
      "Epoch: 064, Loss: 1.8980, Acc: 0.2411\n",
      "Epoch: 065, Loss: 1.8991, Acc: 0.2392\n",
      "Epoch: 066, Loss: 1.8928, Acc: 0.2400\n",
      "Epoch: 067, Loss: 1.8860, Acc: 0.2431\n",
      "Epoch: 068, Loss: 1.8950, Acc: 0.2481\n",
      "Epoch: 069, Loss: 1.8855, Acc: 0.2443\n",
      "Epoch: 070, Loss: 1.8875, Acc: 0.2400\n",
      "Epoch: 071, Loss: 1.8753, Acc: 0.2435\n",
      "Epoch: 072, Loss: 1.8755, Acc: 0.2458\n",
      "Epoch: 073, Loss: 1.8749, Acc: 0.2466\n",
      "Epoch: 074, Loss: 1.8628, Acc: 0.2474\n",
      "Epoch: 075, Loss: 1.8676, Acc: 0.2474\n",
      "Epoch: 076, Loss: 1.8653, Acc: 0.2439\n",
      "Epoch: 077, Loss: 1.8590, Acc: 0.2485\n",
      "Epoch: 078, Loss: 1.8597, Acc: 0.2556\n",
      "Epoch: 079, Loss: 1.8557, Acc: 0.2524\n",
      "Epoch: 080, Loss: 1.8535, Acc: 0.2559\n",
      "Epoch: 081, Loss: 1.8491, Acc: 0.2552\n",
      "Epoch: 082, Loss: 1.8454, Acc: 0.2524\n",
      "Epoch: 083, Loss: 1.8434, Acc: 0.2489\n",
      "Epoch: 084, Loss: 1.8485, Acc: 0.2524\n",
      "Epoch: 085, Loss: 1.8430, Acc: 0.2556\n",
      "Epoch: 086, Loss: 1.8450, Acc: 0.2575\n",
      "Epoch: 087, Loss: 1.8443, Acc: 0.2548\n",
      "Epoch: 088, Loss: 1.8291, Acc: 0.2559\n",
      "Epoch: 089, Loss: 1.8402, Acc: 0.2544\n",
      "Epoch: 090, Loss: 1.8318, Acc: 0.2614\n",
      "Epoch: 091, Loss: 1.8293, Acc: 0.2618\n",
      "Epoch: 092, Loss: 1.8359, Acc: 0.2587\n",
      "Epoch: 093, Loss: 1.8231, Acc: 0.2606\n",
      "Epoch: 094, Loss: 1.8235, Acc: 0.2563\n",
      "Epoch: 095, Loss: 1.8293, Acc: 0.2559\n",
      "Epoch: 096, Loss: 1.8182, Acc: 0.2552\n",
      "Epoch: 097, Loss: 1.8327, Acc: 0.2579\n",
      "Epoch: 098, Loss: 1.8256, Acc: 0.2532\n",
      "Epoch: 099, Loss: 1.8240, Acc: 0.2532\n"
     ]
    }
   ],
   "source": [
    "GraphSAGE16_model = GraphSAGE(data, 16)\n",
    "train_model(GraphSAGE16_model, data, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62a90e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GraphSAGE16_model.eval()\n",
    "#out = GraphSAGE16_model(data.x, data.edge_index)\n",
    "#visualize(out, color=data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db103d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 3.4114, Acc: 0.1032\n",
      "Epoch: 001, Loss: 3.0784, Acc: 0.1457\n",
      "Epoch: 002, Loss: 2.5344, Acc: 0.1511\n",
      "Epoch: 003, Loss: 2.3017, Acc: 0.1453\n",
      "Epoch: 004, Loss: 2.2493, Acc: 0.1473\n",
      "Epoch: 005, Loss: 2.2343, Acc: 0.1574\n",
      "Epoch: 006, Loss: 2.2141, Acc: 0.1695\n",
      "Epoch: 007, Loss: 2.1937, Acc: 0.1800\n",
      "Epoch: 008, Loss: 2.1671, Acc: 0.1882\n",
      "Epoch: 009, Loss: 2.1283, Acc: 0.2014\n",
      "Epoch: 010, Loss: 2.1067, Acc: 0.2174\n",
      "Epoch: 011, Loss: 2.0804, Acc: 0.2287\n",
      "Epoch: 012, Loss: 2.0572, Acc: 0.2256\n",
      "Epoch: 013, Loss: 2.0334, Acc: 0.2291\n",
      "Epoch: 014, Loss: 2.0092, Acc: 0.2330\n",
      "Epoch: 015, Loss: 1.9770, Acc: 0.2341\n",
      "Epoch: 016, Loss: 1.9559, Acc: 0.2454\n",
      "Epoch: 017, Loss: 1.9450, Acc: 0.2446\n",
      "Epoch: 018, Loss: 1.9308, Acc: 0.2415\n",
      "Epoch: 019, Loss: 1.9020, Acc: 0.2415\n",
      "Epoch: 020, Loss: 1.8986, Acc: 0.2485\n",
      "Epoch: 021, Loss: 1.8806, Acc: 0.2598\n",
      "Epoch: 022, Loss: 1.8651, Acc: 0.2653\n",
      "Epoch: 023, Loss: 1.8553, Acc: 0.2626\n",
      "Epoch: 024, Loss: 1.8474, Acc: 0.2594\n",
      "Epoch: 025, Loss: 1.8226, Acc: 0.2579\n",
      "Epoch: 026, Loss: 1.8201, Acc: 0.2575\n",
      "Epoch: 027, Loss: 1.8159, Acc: 0.2610\n",
      "Epoch: 028, Loss: 1.7952, Acc: 0.2614\n",
      "Epoch: 029, Loss: 1.7817, Acc: 0.2618\n",
      "Epoch: 030, Loss: 1.7727, Acc: 0.2696\n",
      "Epoch: 031, Loss: 1.7633, Acc: 0.2758\n",
      "Epoch: 032, Loss: 1.7461, Acc: 0.2770\n",
      "Epoch: 033, Loss: 1.7423, Acc: 0.2867\n",
      "Epoch: 034, Loss: 1.7293, Acc: 0.2879\n",
      "Epoch: 035, Loss: 1.7257, Acc: 0.2910\n",
      "Epoch: 036, Loss: 1.7151, Acc: 0.2953\n",
      "Epoch: 037, Loss: 1.7017, Acc: 0.2949\n",
      "Epoch: 038, Loss: 1.7003, Acc: 0.2949\n",
      "Epoch: 039, Loss: 1.6841, Acc: 0.2957\n",
      "Epoch: 040, Loss: 1.6816, Acc: 0.2961\n",
      "Epoch: 041, Loss: 1.6805, Acc: 0.3023\n",
      "Epoch: 042, Loss: 1.6739, Acc: 0.3011\n",
      "Epoch: 043, Loss: 1.6742, Acc: 0.3062\n",
      "Epoch: 044, Loss: 1.6618, Acc: 0.3081\n",
      "Epoch: 045, Loss: 1.6538, Acc: 0.3097\n",
      "Epoch: 046, Loss: 1.6469, Acc: 0.3089\n",
      "Epoch: 047, Loss: 1.6424, Acc: 0.3116\n",
      "Epoch: 048, Loss: 1.6439, Acc: 0.3136\n",
      "Epoch: 049, Loss: 1.6412, Acc: 0.3128\n",
      "Epoch: 050, Loss: 1.6355, Acc: 0.3140\n",
      "Epoch: 051, Loss: 1.6395, Acc: 0.3198\n",
      "Epoch: 052, Loss: 1.6305, Acc: 0.3183\n",
      "Epoch: 053, Loss: 1.6150, Acc: 0.3159\n",
      "Epoch: 054, Loss: 1.6159, Acc: 0.3226\n",
      "Epoch: 055, Loss: 1.6143, Acc: 0.3198\n",
      "Epoch: 056, Loss: 1.6187, Acc: 0.3175\n",
      "Epoch: 057, Loss: 1.6070, Acc: 0.3163\n",
      "Epoch: 058, Loss: 1.6077, Acc: 0.3198\n",
      "Epoch: 059, Loss: 1.6039, Acc: 0.3218\n",
      "Epoch: 060, Loss: 1.6043, Acc: 0.3206\n",
      "Epoch: 061, Loss: 1.6041, Acc: 0.3222\n",
      "Epoch: 062, Loss: 1.5923, Acc: 0.3218\n",
      "Epoch: 063, Loss: 1.5926, Acc: 0.3288\n",
      "Epoch: 064, Loss: 1.5948, Acc: 0.3241\n",
      "Epoch: 065, Loss: 1.5926, Acc: 0.3261\n",
      "Epoch: 066, Loss: 1.5927, Acc: 0.3288\n",
      "Epoch: 067, Loss: 1.5791, Acc: 0.3233\n",
      "Epoch: 068, Loss: 1.5819, Acc: 0.3229\n",
      "Epoch: 069, Loss: 1.5855, Acc: 0.3226\n",
      "Epoch: 070, Loss: 1.5826, Acc: 0.3280\n",
      "Epoch: 071, Loss: 1.5847, Acc: 0.3268\n",
      "Epoch: 072, Loss: 1.5761, Acc: 0.3249\n",
      "Epoch: 073, Loss: 1.5625, Acc: 0.3257\n",
      "Epoch: 074, Loss: 1.5653, Acc: 0.3296\n",
      "Epoch: 075, Loss: 1.5631, Acc: 0.3249\n",
      "Epoch: 076, Loss: 1.5563, Acc: 0.3229\n",
      "Epoch: 077, Loss: 1.5522, Acc: 0.3268\n",
      "Epoch: 078, Loss: 1.5692, Acc: 0.3276\n",
      "Epoch: 079, Loss: 1.5669, Acc: 0.3288\n",
      "Epoch: 080, Loss: 1.5457, Acc: 0.3276\n",
      "Epoch: 081, Loss: 1.5515, Acc: 0.3284\n",
      "Epoch: 082, Loss: 1.5545, Acc: 0.3265\n",
      "Epoch: 083, Loss: 1.5500, Acc: 0.3237\n",
      "Epoch: 084, Loss: 1.5532, Acc: 0.3292\n",
      "Epoch: 085, Loss: 1.5375, Acc: 0.3261\n",
      "Epoch: 086, Loss: 1.5389, Acc: 0.3296\n",
      "Epoch: 087, Loss: 1.5440, Acc: 0.3346\n",
      "Epoch: 088, Loss: 1.5425, Acc: 0.3226\n",
      "Epoch: 089, Loss: 1.5554, Acc: 0.3280\n",
      "Epoch: 090, Loss: 1.5492, Acc: 0.3315\n",
      "Epoch: 091, Loss: 1.5385, Acc: 0.3296\n",
      "Epoch: 092, Loss: 1.5338, Acc: 0.3327\n",
      "Epoch: 093, Loss: 1.5342, Acc: 0.3315\n",
      "Epoch: 094, Loss: 1.5338, Acc: 0.3296\n",
      "Epoch: 095, Loss: 1.5431, Acc: 0.3311\n",
      "Epoch: 096, Loss: 1.5335, Acc: 0.3339\n",
      "Epoch: 097, Loss: 1.5306, Acc: 0.3319\n",
      "Epoch: 098, Loss: 1.5246, Acc: 0.3265\n",
      "Epoch: 099, Loss: 1.5270, Acc: 0.3303\n"
     ]
    }
   ],
   "source": [
    "GraphSAGE64_model = GraphSAGE(data, 64)\n",
    "train_model(GraphSAGE64_model, data, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c1930a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 4.0253, Acc: 0.1691\n",
      "Epoch: 001, Loss: 7.4160, Acc: 0.1515\n",
      "Epoch: 002, Loss: 6.4005, Acc: 0.1772\n",
      "Epoch: 003, Loss: 3.5701, Acc: 0.1850\n",
      "Epoch: 004, Loss: 2.3770, Acc: 0.2080\n",
      "Epoch: 005, Loss: 2.2163, Acc: 0.1998\n",
      "Epoch: 006, Loss: 2.2426, Acc: 0.1671\n",
      "Epoch: 007, Loss: 2.2208, Acc: 0.1745\n",
      "Epoch: 008, Loss: 2.1406, Acc: 0.2143\n",
      "Epoch: 009, Loss: 2.0885, Acc: 0.2291\n",
      "Epoch: 010, Loss: 2.0578, Acc: 0.2497\n",
      "Epoch: 011, Loss: 2.0247, Acc: 0.2704\n",
      "Epoch: 012, Loss: 1.9782, Acc: 0.2602\n",
      "Epoch: 013, Loss: 1.9455, Acc: 0.2746\n",
      "Epoch: 014, Loss: 1.9131, Acc: 0.2855\n",
      "Epoch: 015, Loss: 1.8874, Acc: 0.3019\n",
      "Epoch: 016, Loss: 1.8581, Acc: 0.3027\n",
      "Epoch: 017, Loss: 1.8336, Acc: 0.3050\n",
      "Epoch: 018, Loss: 1.8118, Acc: 0.3183\n",
      "Epoch: 019, Loss: 1.7810, Acc: 0.3179\n",
      "Epoch: 020, Loss: 1.7822, Acc: 0.3179\n",
      "Epoch: 021, Loss: 1.7544, Acc: 0.3132\n",
      "Epoch: 022, Loss: 1.7449, Acc: 0.3093\n",
      "Epoch: 023, Loss: 1.7409, Acc: 0.3105\n",
      "Epoch: 024, Loss: 1.7053, Acc: 0.3101\n",
      "Epoch: 025, Loss: 1.7051, Acc: 0.3070\n",
      "Epoch: 026, Loss: 1.6980, Acc: 0.3046\n",
      "Epoch: 027, Loss: 1.6870, Acc: 0.3132\n",
      "Epoch: 028, Loss: 1.6742, Acc: 0.3152\n",
      "Epoch: 029, Loss: 1.6553, Acc: 0.3124\n",
      "Epoch: 030, Loss: 1.6622, Acc: 0.3140\n",
      "Epoch: 031, Loss: 1.6459, Acc: 0.3152\n",
      "Epoch: 032, Loss: 1.6349, Acc: 0.3171\n",
      "Epoch: 033, Loss: 1.6262, Acc: 0.3202\n",
      "Epoch: 034, Loss: 1.6291, Acc: 0.3159\n",
      "Epoch: 035, Loss: 1.6235, Acc: 0.3194\n",
      "Epoch: 036, Loss: 1.6206, Acc: 0.3257\n",
      "Epoch: 037, Loss: 1.6112, Acc: 0.3276\n",
      "Epoch: 038, Loss: 1.6080, Acc: 0.3303\n",
      "Epoch: 039, Loss: 1.5988, Acc: 0.3331\n",
      "Epoch: 040, Loss: 1.5878, Acc: 0.3296\n",
      "Epoch: 041, Loss: 1.5820, Acc: 0.3311\n",
      "Epoch: 042, Loss: 1.5829, Acc: 0.3268\n",
      "Epoch: 043, Loss: 1.5735, Acc: 0.3323\n",
      "Epoch: 044, Loss: 1.5720, Acc: 0.3323\n",
      "Epoch: 045, Loss: 1.5602, Acc: 0.3362\n",
      "Epoch: 046, Loss: 1.5568, Acc: 0.3424\n",
      "Epoch: 047, Loss: 1.5586, Acc: 0.3393\n",
      "Epoch: 048, Loss: 1.5447, Acc: 0.3381\n",
      "Epoch: 049, Loss: 1.5355, Acc: 0.3381\n",
      "Epoch: 050, Loss: 1.5259, Acc: 0.3440\n",
      "Epoch: 051, Loss: 1.5349, Acc: 0.3444\n",
      "Epoch: 052, Loss: 1.5410, Acc: 0.3409\n",
      "Epoch: 053, Loss: 1.5249, Acc: 0.3522\n",
      "Epoch: 054, Loss: 1.5087, Acc: 0.3502\n",
      "Epoch: 055, Loss: 1.5151, Acc: 0.3463\n",
      "Epoch: 056, Loss: 1.5105, Acc: 0.3483\n",
      "Epoch: 057, Loss: 1.5090, Acc: 0.3494\n",
      "Epoch: 058, Loss: 1.4974, Acc: 0.3483\n",
      "Epoch: 059, Loss: 1.4957, Acc: 0.3490\n",
      "Epoch: 060, Loss: 1.5017, Acc: 0.3475\n",
      "Epoch: 061, Loss: 1.4925, Acc: 0.3568\n",
      "Epoch: 062, Loss: 1.4853, Acc: 0.3518\n",
      "Epoch: 063, Loss: 1.4923, Acc: 0.3522\n",
      "Epoch: 064, Loss: 1.4843, Acc: 0.3584\n",
      "Epoch: 065, Loss: 1.4661, Acc: 0.3541\n",
      "Epoch: 066, Loss: 1.4628, Acc: 0.3498\n",
      "Epoch: 067, Loss: 1.4660, Acc: 0.3572\n",
      "Epoch: 068, Loss: 1.4624, Acc: 0.3576\n",
      "Epoch: 069, Loss: 1.4561, Acc: 0.3545\n",
      "Epoch: 070, Loss: 1.4610, Acc: 0.3576\n",
      "Epoch: 071, Loss: 1.4502, Acc: 0.3522\n",
      "Epoch: 072, Loss: 1.4509, Acc: 0.3467\n",
      "Epoch: 073, Loss: 1.4495, Acc: 0.3638\n",
      "Epoch: 074, Loss: 1.4448, Acc: 0.3568\n",
      "Epoch: 075, Loss: 1.4359, Acc: 0.3592\n",
      "Epoch: 076, Loss: 1.4308, Acc: 0.3635\n",
      "Epoch: 077, Loss: 1.4350, Acc: 0.3615\n",
      "Epoch: 078, Loss: 1.4305, Acc: 0.3541\n",
      "Epoch: 079, Loss: 1.4360, Acc: 0.3588\n",
      "Epoch: 080, Loss: 1.4304, Acc: 0.3588\n",
      "Epoch: 081, Loss: 1.4307, Acc: 0.3584\n",
      "Epoch: 082, Loss: 1.4227, Acc: 0.3576\n",
      "Epoch: 083, Loss: 1.4210, Acc: 0.3713\n",
      "Epoch: 084, Loss: 1.4157, Acc: 0.3677\n",
      "Epoch: 085, Loss: 1.4236, Acc: 0.3650\n",
      "Epoch: 086, Loss: 1.4154, Acc: 0.3572\n",
      "Epoch: 087, Loss: 1.4029, Acc: 0.3705\n",
      "Epoch: 088, Loss: 1.4030, Acc: 0.3603\n",
      "Epoch: 089, Loss: 1.4082, Acc: 0.3619\n",
      "Epoch: 090, Loss: 1.4044, Acc: 0.3701\n",
      "Epoch: 091, Loss: 1.3957, Acc: 0.3662\n",
      "Epoch: 092, Loss: 1.3930, Acc: 0.3681\n",
      "Epoch: 093, Loss: 1.3893, Acc: 0.3728\n",
      "Epoch: 094, Loss: 1.3838, Acc: 0.3670\n",
      "Epoch: 095, Loss: 1.3840, Acc: 0.3744\n",
      "Epoch: 096, Loss: 1.3885, Acc: 0.3596\n",
      "Epoch: 097, Loss: 1.3888, Acc: 0.3779\n",
      "Epoch: 098, Loss: 1.3881, Acc: 0.3681\n",
      "Epoch: 099, Loss: 1.3843, Acc: 0.3666\n"
     ]
    }
   ],
   "source": [
    "GraphSAGE256_model = GraphSAGE(data, 265)\n",
    "train_model(GraphSAGE256_model, data, 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b04769d",
   "metadata": {},
   "source": [
    "## GraphSAGE 2 - 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fe325a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 2.6736, Acc: 0.1021\n",
      "Epoch: 001, Loss: 2.4608, Acc: 0.1079\n",
      "Epoch: 002, Loss: 2.3645, Acc: 0.1056\n",
      "Epoch: 003, Loss: 2.3282, Acc: 0.0962\n",
      "Epoch: 004, Loss: 2.3074, Acc: 0.0958\n",
      "Epoch: 005, Loss: 2.2942, Acc: 0.0947\n",
      "Epoch: 006, Loss: 2.2841, Acc: 0.0904\n",
      "Epoch: 007, Loss: 2.2732, Acc: 0.0904\n",
      "Epoch: 008, Loss: 2.2582, Acc: 0.0954\n",
      "Epoch: 009, Loss: 2.2431, Acc: 0.0943\n",
      "Epoch: 010, Loss: 2.2352, Acc: 0.1009\n",
      "Epoch: 011, Loss: 2.2188, Acc: 0.1145\n",
      "Epoch: 012, Loss: 2.2075, Acc: 0.1223\n",
      "Epoch: 013, Loss: 2.1990, Acc: 0.1266\n",
      "Epoch: 014, Loss: 2.1893, Acc: 0.1344\n",
      "Epoch: 015, Loss: 2.1789, Acc: 0.1379\n",
      "Epoch: 016, Loss: 2.1686, Acc: 0.1387\n",
      "Epoch: 017, Loss: 2.1622, Acc: 0.1363\n",
      "Epoch: 018, Loss: 2.1477, Acc: 0.1383\n",
      "Epoch: 019, Loss: 2.1380, Acc: 0.1418\n",
      "Epoch: 020, Loss: 2.1281, Acc: 0.1375\n",
      "Epoch: 021, Loss: 2.1208, Acc: 0.1371\n",
      "Epoch: 022, Loss: 2.1116, Acc: 0.1414\n",
      "Epoch: 023, Loss: 2.1056, Acc: 0.1426\n",
      "Epoch: 024, Loss: 2.0894, Acc: 0.1367\n",
      "Epoch: 025, Loss: 2.0835, Acc: 0.1375\n",
      "Epoch: 026, Loss: 2.0712, Acc: 0.1441\n",
      "Epoch: 027, Loss: 2.0646, Acc: 0.1500\n",
      "Epoch: 028, Loss: 2.0543, Acc: 0.1515\n",
      "Epoch: 029, Loss: 2.0619, Acc: 0.1519\n",
      "Epoch: 030, Loss: 2.0534, Acc: 0.1550\n",
      "Epoch: 031, Loss: 2.0410, Acc: 0.1515\n",
      "Epoch: 032, Loss: 2.0349, Acc: 0.1578\n",
      "Epoch: 033, Loss: 2.0282, Acc: 0.1597\n",
      "Epoch: 034, Loss: 2.0361, Acc: 0.1617\n",
      "Epoch: 035, Loss: 2.0251, Acc: 0.1636\n",
      "Epoch: 036, Loss: 2.0267, Acc: 0.1652\n",
      "Epoch: 037, Loss: 2.0142, Acc: 0.1621\n",
      "Epoch: 038, Loss: 2.0121, Acc: 0.1621\n",
      "Epoch: 039, Loss: 2.0067, Acc: 0.1632\n",
      "Epoch: 040, Loss: 1.9996, Acc: 0.1656\n",
      "Epoch: 041, Loss: 2.0021, Acc: 0.1683\n",
      "Epoch: 042, Loss: 2.0002, Acc: 0.1667\n",
      "Epoch: 043, Loss: 1.9850, Acc: 0.1648\n",
      "Epoch: 044, Loss: 1.9994, Acc: 0.1609\n",
      "Epoch: 045, Loss: 2.0033, Acc: 0.1601\n",
      "Epoch: 046, Loss: 1.9909, Acc: 0.1628\n",
      "Epoch: 047, Loss: 1.9940, Acc: 0.1640\n",
      "Epoch: 048, Loss: 1.9932, Acc: 0.1593\n",
      "Epoch: 049, Loss: 1.9807, Acc: 0.1597\n",
      "Epoch: 050, Loss: 1.9850, Acc: 0.1586\n",
      "Epoch: 051, Loss: 1.9803, Acc: 0.1589\n",
      "Epoch: 052, Loss: 1.9790, Acc: 0.1605\n",
      "Epoch: 053, Loss: 1.9716, Acc: 0.1621\n",
      "Epoch: 054, Loss: 1.9798, Acc: 0.1660\n",
      "Epoch: 055, Loss: 1.9635, Acc: 0.1667\n",
      "Epoch: 056, Loss: 1.9622, Acc: 0.1683\n",
      "Epoch: 057, Loss: 1.9694, Acc: 0.1695\n",
      "Epoch: 058, Loss: 1.9663, Acc: 0.1660\n",
      "Epoch: 059, Loss: 1.9712, Acc: 0.1628\n",
      "Epoch: 060, Loss: 1.9682, Acc: 0.1652\n",
      "Epoch: 061, Loss: 1.9697, Acc: 0.1644\n",
      "Epoch: 062, Loss: 1.9633, Acc: 0.1648\n",
      "Epoch: 063, Loss: 1.9611, Acc: 0.1671\n",
      "Epoch: 064, Loss: 1.9671, Acc: 0.1582\n",
      "Epoch: 065, Loss: 1.9634, Acc: 0.1574\n",
      "Epoch: 066, Loss: 1.9556, Acc: 0.1570\n",
      "Epoch: 067, Loss: 1.9627, Acc: 0.1558\n",
      "Epoch: 068, Loss: 1.9541, Acc: 0.1636\n",
      "Epoch: 069, Loss: 1.9618, Acc: 0.1648\n",
      "Epoch: 070, Loss: 1.9650, Acc: 0.1636\n",
      "Epoch: 071, Loss: 1.9580, Acc: 0.1628\n",
      "Epoch: 072, Loss: 1.9525, Acc: 0.1617\n",
      "Epoch: 073, Loss: 1.9509, Acc: 0.1632\n",
      "Epoch: 074, Loss: 1.9552, Acc: 0.1609\n",
      "Epoch: 075, Loss: 1.9542, Acc: 0.1566\n",
      "Epoch: 076, Loss: 1.9538, Acc: 0.1543\n",
      "Epoch: 077, Loss: 1.9549, Acc: 0.1570\n",
      "Epoch: 078, Loss: 1.9513, Acc: 0.1617\n",
      "Epoch: 079, Loss: 1.9485, Acc: 0.1527\n",
      "Epoch: 080, Loss: 1.9429, Acc: 0.1574\n",
      "Epoch: 081, Loss: 1.9465, Acc: 0.1589\n",
      "Epoch: 082, Loss: 1.9441, Acc: 0.1550\n",
      "Epoch: 083, Loss: 1.9473, Acc: 0.1574\n",
      "Epoch: 084, Loss: 1.9453, Acc: 0.1601\n",
      "Epoch: 085, Loss: 1.9456, Acc: 0.1562\n",
      "Epoch: 086, Loss: 1.9385, Acc: 0.1562\n",
      "Epoch: 087, Loss: 1.9412, Acc: 0.1558\n",
      "Epoch: 088, Loss: 1.9426, Acc: 0.1597\n",
      "Epoch: 089, Loss: 1.9408, Acc: 0.1570\n",
      "Epoch: 090, Loss: 1.9378, Acc: 0.1574\n",
      "Epoch: 091, Loss: 1.9417, Acc: 0.1558\n",
      "Epoch: 092, Loss: 1.9437, Acc: 0.1597\n",
      "Epoch: 093, Loss: 1.9406, Acc: 0.1586\n",
      "Epoch: 094, Loss: 1.9387, Acc: 0.1531\n",
      "Epoch: 095, Loss: 1.9480, Acc: 0.1511\n",
      "Epoch: 096, Loss: 1.9423, Acc: 0.1593\n",
      "Epoch: 097, Loss: 1.9186, Acc: 0.1550\n",
      "Epoch: 098, Loss: 1.9439, Acc: 0.1511\n",
      "Epoch: 099, Loss: 1.9270, Acc: 0.1558\n"
     ]
    }
   ],
   "source": [
    "GraphSAGE2_16_model = GraphSAGE2(data, 16, 16)\n",
    "train_model(GraphSAGE2_16_model, data, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ddad4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 2.8492, Acc: 0.1060\n",
      "Epoch: 001, Loss: 2.5663, Acc: 0.1130\n",
      "Epoch: 002, Loss: 2.3534, Acc: 0.1110\n",
      "Epoch: 003, Loss: 2.3004, Acc: 0.1126\n",
      "Epoch: 004, Loss: 2.2755, Acc: 0.1196\n",
      "Epoch: 005, Loss: 2.2490, Acc: 0.1418\n",
      "Epoch: 006, Loss: 2.2102, Acc: 0.1593\n",
      "Epoch: 007, Loss: 2.1682, Acc: 0.1628\n",
      "Epoch: 008, Loss: 2.1300, Acc: 0.1648\n",
      "Epoch: 009, Loss: 2.0862, Acc: 0.1753\n",
      "Epoch: 010, Loss: 2.0599, Acc: 0.1924\n",
      "Epoch: 011, Loss: 2.0306, Acc: 0.2037\n",
      "Epoch: 012, Loss: 2.0079, Acc: 0.2119\n",
      "Epoch: 013, Loss: 1.9943, Acc: 0.2205\n",
      "Epoch: 014, Loss: 1.9643, Acc: 0.2189\n",
      "Epoch: 015, Loss: 1.9610, Acc: 0.2154\n",
      "Epoch: 016, Loss: 1.9234, Acc: 0.2220\n",
      "Epoch: 017, Loss: 1.9213, Acc: 0.2435\n",
      "Epoch: 018, Loss: 1.8963, Acc: 0.2513\n",
      "Epoch: 019, Loss: 1.8872, Acc: 0.2524\n",
      "Epoch: 020, Loss: 1.8703, Acc: 0.2668\n",
      "Epoch: 021, Loss: 1.8675, Acc: 0.2548\n",
      "Epoch: 022, Loss: 1.8394, Acc: 0.2668\n",
      "Epoch: 023, Loss: 1.8267, Acc: 0.2618\n",
      "Epoch: 024, Loss: 1.8195, Acc: 0.2559\n",
      "Epoch: 025, Loss: 1.7934, Acc: 0.2598\n",
      "Epoch: 026, Loss: 1.7905, Acc: 0.2653\n",
      "Epoch: 027, Loss: 1.7978, Acc: 0.2711\n",
      "Epoch: 028, Loss: 1.7682, Acc: 0.2750\n",
      "Epoch: 029, Loss: 1.7620, Acc: 0.2879\n",
      "Epoch: 030, Loss: 1.7605, Acc: 0.2824\n",
      "Epoch: 031, Loss: 1.7571, Acc: 0.2746\n",
      "Epoch: 032, Loss: 1.7374, Acc: 0.2820\n",
      "Epoch: 033, Loss: 1.7313, Acc: 0.2781\n",
      "Epoch: 034, Loss: 1.7190, Acc: 0.2754\n",
      "Epoch: 035, Loss: 1.7116, Acc: 0.2848\n",
      "Epoch: 036, Loss: 1.7157, Acc: 0.2852\n",
      "Epoch: 037, Loss: 1.7023, Acc: 0.2820\n",
      "Epoch: 038, Loss: 1.6912, Acc: 0.2933\n",
      "Epoch: 039, Loss: 1.6807, Acc: 0.2894\n",
      "Epoch: 040, Loss: 1.6773, Acc: 0.2789\n",
      "Epoch: 041, Loss: 1.6733, Acc: 0.2929\n",
      "Epoch: 042, Loss: 1.6696, Acc: 0.2902\n",
      "Epoch: 043, Loss: 1.6502, Acc: 0.2914\n",
      "Epoch: 044, Loss: 1.6416, Acc: 0.2968\n",
      "Epoch: 045, Loss: 1.6469, Acc: 0.2766\n",
      "Epoch: 046, Loss: 1.6361, Acc: 0.3066\n",
      "Epoch: 047, Loss: 1.6192, Acc: 0.3054\n",
      "Epoch: 048, Loss: 1.6097, Acc: 0.2949\n",
      "Epoch: 049, Loss: 1.6166, Acc: 0.2898\n",
      "Epoch: 050, Loss: 1.6176, Acc: 0.2988\n",
      "Epoch: 051, Loss: 1.6079, Acc: 0.3031\n",
      "Epoch: 052, Loss: 1.6028, Acc: 0.3004\n",
      "Epoch: 053, Loss: 1.5927, Acc: 0.3074\n",
      "Epoch: 054, Loss: 1.5864, Acc: 0.3027\n",
      "Epoch: 055, Loss: 1.5908, Acc: 0.3074\n",
      "Epoch: 056, Loss: 1.5769, Acc: 0.3007\n",
      "Epoch: 057, Loss: 1.5831, Acc: 0.3116\n",
      "Epoch: 058, Loss: 1.5736, Acc: 0.3144\n",
      "Epoch: 059, Loss: 1.5818, Acc: 0.3000\n",
      "Epoch: 060, Loss: 1.5681, Acc: 0.3011\n",
      "Epoch: 061, Loss: 1.5640, Acc: 0.3116\n",
      "Epoch: 062, Loss: 1.5564, Acc: 0.3128\n",
      "Epoch: 063, Loss: 1.5554, Acc: 0.3078\n",
      "Epoch: 064, Loss: 1.5458, Acc: 0.3039\n",
      "Epoch: 065, Loss: 1.5387, Acc: 0.3066\n",
      "Epoch: 066, Loss: 1.5493, Acc: 0.3120\n",
      "Epoch: 067, Loss: 1.5351, Acc: 0.3128\n",
      "Epoch: 068, Loss: 1.5326, Acc: 0.2988\n",
      "Epoch: 069, Loss: 1.5464, Acc: 0.3046\n",
      "Epoch: 070, Loss: 1.5387, Acc: 0.3128\n",
      "Epoch: 071, Loss: 1.5297, Acc: 0.3042\n",
      "Epoch: 072, Loss: 1.5300, Acc: 0.3171\n",
      "Epoch: 073, Loss: 1.5220, Acc: 0.3054\n",
      "Epoch: 074, Loss: 1.5334, Acc: 0.3050\n",
      "Epoch: 075, Loss: 1.5224, Acc: 0.3101\n",
      "Epoch: 076, Loss: 1.5156, Acc: 0.3066\n",
      "Epoch: 077, Loss: 1.5157, Acc: 0.3128\n",
      "Epoch: 078, Loss: 1.5152, Acc: 0.3085\n",
      "Epoch: 079, Loss: 1.5253, Acc: 0.3175\n",
      "Epoch: 080, Loss: 1.5108, Acc: 0.3078\n",
      "Epoch: 081, Loss: 1.5042, Acc: 0.3019\n",
      "Epoch: 082, Loss: 1.5227, Acc: 0.3190\n",
      "Epoch: 083, Loss: 1.5044, Acc: 0.3058\n",
      "Epoch: 084, Loss: 1.4987, Acc: 0.3163\n",
      "Epoch: 085, Loss: 1.4959, Acc: 0.3144\n",
      "Epoch: 086, Loss: 1.4858, Acc: 0.3074\n",
      "Epoch: 087, Loss: 1.4916, Acc: 0.3144\n",
      "Epoch: 088, Loss: 1.4866, Acc: 0.3000\n",
      "Epoch: 089, Loss: 1.4955, Acc: 0.3148\n",
      "Epoch: 090, Loss: 1.4913, Acc: 0.3113\n",
      "Epoch: 091, Loss: 1.4826, Acc: 0.3105\n",
      "Epoch: 092, Loss: 1.4834, Acc: 0.3155\n",
      "Epoch: 093, Loss: 1.4832, Acc: 0.3074\n",
      "Epoch: 094, Loss: 1.4751, Acc: 0.3140\n",
      "Epoch: 095, Loss: 1.4635, Acc: 0.3206\n",
      "Epoch: 096, Loss: 1.4873, Acc: 0.3042\n",
      "Epoch: 097, Loss: 1.4786, Acc: 0.3062\n",
      "Epoch: 098, Loss: 1.4939, Acc: 0.3101\n",
      "Epoch: 099, Loss: 1.4749, Acc: 0.3159\n"
     ]
    }
   ],
   "source": [
    "GraphSAGE2_64_model = GraphSAGE2(data, hidden_channels1=64, hidden_channels2=64)\n",
    "train_model(GraphSAGE2_64_model, data, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcba02ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 3.5921, Acc: 0.1083\n",
      "Epoch: 001, Loss: 16.0753, Acc: 0.0982\n",
      "Epoch: 002, Loss: 8.5354, Acc: 0.1130\n",
      "Epoch: 003, Loss: 3.5263, Acc: 0.1126\n",
      "Epoch: 004, Loss: 2.4453, Acc: 0.1138\n",
      "Epoch: 005, Loss: 2.3110, Acc: 0.1134\n",
      "Epoch: 006, Loss: 2.2978, Acc: 0.1176\n",
      "Epoch: 007, Loss: 2.2912, Acc: 0.1188\n",
      "Epoch: 008, Loss: 2.2814, Acc: 0.1289\n",
      "Epoch: 009, Loss: 2.2615, Acc: 0.1352\n",
      "Epoch: 010, Loss: 2.2283, Acc: 0.1558\n",
      "Epoch: 011, Loss: 2.1995, Acc: 0.1492\n",
      "Epoch: 012, Loss: 2.1692, Acc: 0.1523\n",
      "Epoch: 013, Loss: 2.1523, Acc: 0.1601\n",
      "Epoch: 014, Loss: 2.1327, Acc: 0.1730\n",
      "Epoch: 015, Loss: 2.1083, Acc: 0.1722\n",
      "Epoch: 016, Loss: 2.0847, Acc: 0.1636\n",
      "Epoch: 017, Loss: 2.0684, Acc: 0.1769\n",
      "Epoch: 018, Loss: 2.0506, Acc: 0.1660\n",
      "Epoch: 019, Loss: 2.0463, Acc: 0.1698\n",
      "Epoch: 020, Loss: 2.0286, Acc: 0.1745\n",
      "Epoch: 021, Loss: 2.0128, Acc: 0.1780\n",
      "Epoch: 022, Loss: 2.0022, Acc: 0.1870\n",
      "Epoch: 023, Loss: 1.9944, Acc: 0.1917\n",
      "Epoch: 024, Loss: 1.9840, Acc: 0.1952\n",
      "Epoch: 025, Loss: 1.9856, Acc: 0.1839\n",
      "Epoch: 026, Loss: 1.9799, Acc: 0.1878\n",
      "Epoch: 027, Loss: 1.9721, Acc: 0.1936\n",
      "Epoch: 028, Loss: 1.9658, Acc: 0.1952\n",
      "Epoch: 029, Loss: 1.9534, Acc: 0.1921\n",
      "Epoch: 030, Loss: 1.9460, Acc: 0.1936\n",
      "Epoch: 031, Loss: 1.9409, Acc: 0.1897\n",
      "Epoch: 032, Loss: 1.9414, Acc: 0.1979\n",
      "Epoch: 033, Loss: 1.9238, Acc: 0.1917\n",
      "Epoch: 034, Loss: 1.9358, Acc: 0.1967\n",
      "Epoch: 035, Loss: 1.9187, Acc: 0.2108\n",
      "Epoch: 036, Loss: 1.9176, Acc: 0.2053\n",
      "Epoch: 037, Loss: 1.8970, Acc: 0.2088\n",
      "Epoch: 038, Loss: 1.9032, Acc: 0.2131\n",
      "Epoch: 039, Loss: 1.8875, Acc: 0.2135\n",
      "Epoch: 040, Loss: 1.8853, Acc: 0.2053\n",
      "Epoch: 041, Loss: 1.8666, Acc: 0.2193\n",
      "Epoch: 042, Loss: 1.8637, Acc: 0.2415\n",
      "Epoch: 043, Loss: 1.8585, Acc: 0.2388\n",
      "Epoch: 044, Loss: 1.8532, Acc: 0.2174\n",
      "Epoch: 045, Loss: 1.8383, Acc: 0.2100\n",
      "Epoch: 046, Loss: 1.8358, Acc: 0.2326\n",
      "Epoch: 047, Loss: 1.8251, Acc: 0.2400\n",
      "Epoch: 048, Loss: 1.8314, Acc: 0.2369\n",
      "Epoch: 049, Loss: 1.8105, Acc: 0.2224\n",
      "Epoch: 050, Loss: 1.8157, Acc: 0.2287\n",
      "Epoch: 051, Loss: 1.7966, Acc: 0.2427\n",
      "Epoch: 052, Loss: 1.7993, Acc: 0.2314\n",
      "Epoch: 053, Loss: 1.7821, Acc: 0.2279\n",
      "Epoch: 054, Loss: 1.7925, Acc: 0.2318\n",
      "Epoch: 055, Loss: 1.7819, Acc: 0.2396\n",
      "Epoch: 056, Loss: 1.7900, Acc: 0.2369\n",
      "Epoch: 057, Loss: 1.7655, Acc: 0.2302\n",
      "Epoch: 058, Loss: 1.7658, Acc: 0.2333\n",
      "Epoch: 059, Loss: 1.7646, Acc: 0.2333\n",
      "Epoch: 060, Loss: 1.7531, Acc: 0.2236\n",
      "Epoch: 061, Loss: 1.7577, Acc: 0.2411\n",
      "Epoch: 062, Loss: 1.7558, Acc: 0.2376\n",
      "Epoch: 063, Loss: 1.7578, Acc: 0.2353\n",
      "Epoch: 064, Loss: 1.7512, Acc: 0.2267\n",
      "Epoch: 065, Loss: 1.7361, Acc: 0.2388\n",
      "Epoch: 066, Loss: 1.7403, Acc: 0.2466\n",
      "Epoch: 067, Loss: 1.7407, Acc: 0.2392\n",
      "Epoch: 068, Loss: 1.7342, Acc: 0.2306\n",
      "Epoch: 069, Loss: 1.7230, Acc: 0.2287\n",
      "Epoch: 070, Loss: 1.7215, Acc: 0.2372\n",
      "Epoch: 071, Loss: 1.7307, Acc: 0.2388\n",
      "Epoch: 072, Loss: 1.7208, Acc: 0.2353\n",
      "Epoch: 073, Loss: 1.7125, Acc: 0.2443\n",
      "Epoch: 074, Loss: 1.7105, Acc: 0.2279\n",
      "Epoch: 075, Loss: 1.7175, Acc: 0.2423\n",
      "Epoch: 076, Loss: 1.6991, Acc: 0.2400\n",
      "Epoch: 077, Loss: 1.6942, Acc: 0.2563\n",
      "Epoch: 078, Loss: 1.7044, Acc: 0.2209\n",
      "Epoch: 079, Loss: 1.7467, Acc: 0.2400\n",
      "Epoch: 080, Loss: 1.7014, Acc: 0.2443\n",
      "Epoch: 081, Loss: 1.7026, Acc: 0.2380\n",
      "Epoch: 082, Loss: 1.6995, Acc: 0.2333\n",
      "Epoch: 083, Loss: 1.6829, Acc: 0.2501\n",
      "Epoch: 084, Loss: 1.6907, Acc: 0.2536\n",
      "Epoch: 085, Loss: 1.6951, Acc: 0.2524\n",
      "Epoch: 086, Loss: 1.6852, Acc: 0.2509\n",
      "Epoch: 087, Loss: 1.6767, Acc: 0.2478\n",
      "Epoch: 088, Loss: 1.6853, Acc: 0.2392\n",
      "Epoch: 089, Loss: 1.6826, Acc: 0.2485\n",
      "Epoch: 090, Loss: 1.6739, Acc: 0.2641\n",
      "Epoch: 091, Loss: 1.6777, Acc: 0.2641\n",
      "Epoch: 092, Loss: 1.6685, Acc: 0.2493\n",
      "Epoch: 093, Loss: 1.6682, Acc: 0.2466\n",
      "Epoch: 094, Loss: 1.6667, Acc: 0.2470\n",
      "Epoch: 095, Loss: 1.6607, Acc: 0.2575\n",
      "Epoch: 096, Loss: 1.6625, Acc: 0.2567\n",
      "Epoch: 097, Loss: 1.6709, Acc: 0.2466\n",
      "Epoch: 098, Loss: 1.6543, Acc: 0.2489\n",
      "Epoch: 099, Loss: 1.6406, Acc: 0.2571\n"
     ]
    }
   ],
   "source": [
    "GraphSAGE2_256_model = GraphSAGE2(data, hidden_channels1=256, hidden_channels2=256)\n",
    "train_model(GraphSAGE2_256_model, data, 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04be29b0",
   "metadata": {},
   "source": [
    "## Experiments with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73329a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 4.1580, Acc: 0.1414\n",
      "Epoch: 001, Loss: 9.3317, Acc: 0.1289\n",
      "Epoch: 002, Loss: 6.6050, Acc: 0.1554\n",
      "Epoch: 003, Loss: 3.9215, Acc: 0.1578\n",
      "Epoch: 004, Loss: 2.7383, Acc: 0.1741\n",
      "Epoch: 005, Loss: 2.3263, Acc: 0.1488\n",
      "Epoch: 006, Loss: 2.2447, Acc: 0.1480\n",
      "Epoch: 007, Loss: 2.2256, Acc: 0.1434\n",
      "Epoch: 008, Loss: 2.2088, Acc: 0.1414\n",
      "Epoch: 009, Loss: 2.1962, Acc: 0.1422\n",
      "Epoch: 010, Loss: 2.1815, Acc: 0.1508\n",
      "Epoch: 011, Loss: 2.1543, Acc: 0.1574\n",
      "Epoch: 012, Loss: 2.1372, Acc: 0.1671\n",
      "Epoch: 013, Loss: 2.1190, Acc: 0.1808\n",
      "Epoch: 014, Loss: 2.0935, Acc: 0.1839\n",
      "Epoch: 015, Loss: 2.0730, Acc: 0.1995\n",
      "Epoch: 016, Loss: 2.0472, Acc: 0.2287\n",
      "Epoch: 017, Loss: 2.0231, Acc: 0.2392\n",
      "Epoch: 018, Loss: 2.0058, Acc: 0.2333\n",
      "Epoch: 019, Loss: 1.9846, Acc: 0.2411\n",
      "Epoch: 020, Loss: 1.9651, Acc: 0.2489\n",
      "Epoch: 021, Loss: 1.9426, Acc: 0.2497\n",
      "Epoch: 022, Loss: 1.9268, Acc: 0.2450\n",
      "Epoch: 023, Loss: 1.8993, Acc: 0.2485\n",
      "Epoch: 024, Loss: 1.8931, Acc: 0.2579\n",
      "Epoch: 025, Loss: 1.8765, Acc: 0.2633\n",
      "Epoch: 026, Loss: 1.8608, Acc: 0.2692\n",
      "Epoch: 027, Loss: 1.8459, Acc: 0.2637\n",
      "Epoch: 028, Loss: 1.8300, Acc: 0.2649\n",
      "Epoch: 029, Loss: 1.8247, Acc: 0.2672\n",
      "Epoch: 030, Loss: 1.8027, Acc: 0.2743\n",
      "Epoch: 031, Loss: 1.7936, Acc: 0.2711\n",
      "Epoch: 032, Loss: 1.7951, Acc: 0.2723\n",
      "Epoch: 033, Loss: 1.7763, Acc: 0.2727\n",
      "Epoch: 034, Loss: 1.7632, Acc: 0.2766\n",
      "Epoch: 035, Loss: 1.7546, Acc: 0.2817\n",
      "Epoch: 036, Loss: 1.7484, Acc: 0.2774\n",
      "Epoch: 037, Loss: 1.7314, Acc: 0.2797\n",
      "Epoch: 038, Loss: 1.7347, Acc: 0.2817\n",
      "Epoch: 039, Loss: 1.7276, Acc: 0.2805\n",
      "Epoch: 040, Loss: 1.7154, Acc: 0.2891\n",
      "Epoch: 041, Loss: 1.7140, Acc: 0.2906\n",
      "Epoch: 042, Loss: 1.7074, Acc: 0.2891\n",
      "Epoch: 043, Loss: 1.7084, Acc: 0.2906\n",
      "Epoch: 044, Loss: 1.6926, Acc: 0.2933\n",
      "Epoch: 045, Loss: 1.6937, Acc: 0.2933\n",
      "Epoch: 046, Loss: 1.6823, Acc: 0.2972\n",
      "Epoch: 047, Loss: 1.6720, Acc: 0.2984\n",
      "Epoch: 048, Loss: 1.6728, Acc: 0.2996\n",
      "Epoch: 049, Loss: 1.6665, Acc: 0.3031\n",
      "Epoch: 050, Loss: 1.6508, Acc: 0.3105\n",
      "Epoch: 051, Loss: 1.6470, Acc: 0.3144\n",
      "Epoch: 052, Loss: 1.6542, Acc: 0.3140\n",
      "Epoch: 053, Loss: 1.6431, Acc: 0.3198\n",
      "Epoch: 054, Loss: 1.6376, Acc: 0.3175\n",
      "Epoch: 055, Loss: 1.6254, Acc: 0.3163\n",
      "Epoch: 056, Loss: 1.6321, Acc: 0.3175\n",
      "Epoch: 057, Loss: 1.6186, Acc: 0.3210\n",
      "Epoch: 058, Loss: 1.6112, Acc: 0.3202\n",
      "Epoch: 059, Loss: 1.6004, Acc: 0.3249\n",
      "Epoch: 060, Loss: 1.6155, Acc: 0.3268\n",
      "Epoch: 061, Loss: 1.5944, Acc: 0.3296\n",
      "Epoch: 062, Loss: 1.5915, Acc: 0.3284\n",
      "Epoch: 063, Loss: 1.5806, Acc: 0.3311\n",
      "Epoch: 064, Loss: 1.5813, Acc: 0.3307\n",
      "Epoch: 065, Loss: 1.5827, Acc: 0.3284\n",
      "Epoch: 066, Loss: 1.5653, Acc: 0.3335\n",
      "Epoch: 067, Loss: 1.5731, Acc: 0.3276\n",
      "Epoch: 068, Loss: 1.5657, Acc: 0.3268\n",
      "Epoch: 069, Loss: 1.5629, Acc: 0.3335\n",
      "Early stopping at epoch 69\n"
     ]
    }
   ],
   "source": [
    "GraphSAGE256_model = GraphSAGE(data, 256)\n",
    "train_model(GraphSAGE256_model, data, 100, es_patience=10, es_threshold=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eeaa320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 3.4114, Acc: 0.1032\n",
      "Epoch: 001, Loss: 3.0784, Acc: 0.1457\n",
      "Epoch: 002, Loss: 2.5344, Acc: 0.1511\n",
      "Epoch: 003, Loss: 2.3017, Acc: 0.1453\n",
      "Epoch: 004, Loss: 2.2493, Acc: 0.1473\n",
      "Epoch: 005, Loss: 2.2343, Acc: 0.1574\n",
      "Epoch: 006, Loss: 2.2141, Acc: 0.1695\n",
      "Epoch: 007, Loss: 2.1937, Acc: 0.1800\n",
      "Epoch: 008, Loss: 2.1671, Acc: 0.1882\n",
      "Epoch: 009, Loss: 2.1283, Acc: 0.2014\n",
      "Epoch: 010, Loss: 2.1067, Acc: 0.2174\n",
      "Epoch: 011, Loss: 2.0804, Acc: 0.2287\n",
      "Epoch: 012, Loss: 2.0572, Acc: 0.2256\n",
      "Epoch: 013, Loss: 2.0334, Acc: 0.2291\n",
      "Epoch: 014, Loss: 2.0092, Acc: 0.2330\n",
      "Epoch: 015, Loss: 1.9770, Acc: 0.2341\n",
      "Epoch: 016, Loss: 1.9559, Acc: 0.2454\n",
      "Epoch: 017, Loss: 1.9450, Acc: 0.2446\n",
      "Epoch: 018, Loss: 1.9308, Acc: 0.2415\n",
      "Epoch: 019, Loss: 1.9020, Acc: 0.2415\n",
      "Epoch: 020, Loss: 1.8986, Acc: 0.2485\n",
      "Epoch: 021, Loss: 1.8806, Acc: 0.2598\n",
      "Epoch: 022, Loss: 1.8651, Acc: 0.2653\n",
      "Epoch: 023, Loss: 1.8553, Acc: 0.2626\n",
      "Epoch: 024, Loss: 1.8474, Acc: 0.2594\n",
      "Epoch: 025, Loss: 1.8226, Acc: 0.2579\n",
      "Epoch: 026, Loss: 1.8201, Acc: 0.2575\n",
      "Epoch: 027, Loss: 1.8159, Acc: 0.2610\n",
      "Epoch: 028, Loss: 1.7952, Acc: 0.2614\n",
      "Epoch: 029, Loss: 1.7817, Acc: 0.2618\n",
      "Epoch: 030, Loss: 1.7727, Acc: 0.2696\n",
      "Epoch: 031, Loss: 1.7633, Acc: 0.2758\n",
      "Epoch: 032, Loss: 1.7461, Acc: 0.2770\n",
      "Epoch: 033, Loss: 1.7423, Acc: 0.2867\n",
      "Epoch: 034, Loss: 1.7293, Acc: 0.2879\n",
      "Epoch: 035, Loss: 1.7257, Acc: 0.2910\n",
      "Epoch: 036, Loss: 1.7151, Acc: 0.2953\n",
      "Epoch: 037, Loss: 1.7017, Acc: 0.2949\n",
      "Epoch: 038, Loss: 1.7003, Acc: 0.2949\n",
      "Epoch: 039, Loss: 1.6841, Acc: 0.2957\n",
      "Epoch: 040, Loss: 1.6816, Acc: 0.2961\n",
      "Epoch: 041, Loss: 1.6805, Acc: 0.3023\n",
      "Epoch: 042, Loss: 1.6739, Acc: 0.3011\n",
      "Epoch: 043, Loss: 1.6742, Acc: 0.3062\n",
      "Epoch: 044, Loss: 1.6618, Acc: 0.3081\n",
      "Epoch: 045, Loss: 1.6538, Acc: 0.3097\n",
      "Epoch: 046, Loss: 1.6469, Acc: 0.3089\n",
      "Epoch: 047, Loss: 1.6424, Acc: 0.3116\n",
      "Epoch: 048, Loss: 1.6439, Acc: 0.3136\n",
      "Epoch: 049, Loss: 1.6412, Acc: 0.3128\n",
      "Epoch: 050, Loss: 1.6355, Acc: 0.3140\n",
      "Epoch: 051, Loss: 1.6395, Acc: 0.3198\n",
      "Epoch: 052, Loss: 1.6305, Acc: 0.3183\n",
      "Epoch: 053, Loss: 1.6150, Acc: 0.3159\n",
      "Epoch: 054, Loss: 1.6159, Acc: 0.3226\n",
      "Epoch: 055, Loss: 1.6143, Acc: 0.3198\n",
      "Epoch: 056, Loss: 1.6187, Acc: 0.3175\n",
      "Epoch: 057, Loss: 1.6070, Acc: 0.3163\n",
      "Epoch: 058, Loss: 1.6077, Acc: 0.3198\n",
      "Epoch: 059, Loss: 1.6039, Acc: 0.3218\n",
      "Epoch: 060, Loss: 1.6043, Acc: 0.3206\n",
      "Early stopping at epoch 60\n"
     ]
    }
   ],
   "source": [
    "GraphSAGE256_model = GraphSAGE(data, 64)\n",
    "train_model(GraphSAGE256_model, data, 1000, es_patience=10, es_threshold=0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
